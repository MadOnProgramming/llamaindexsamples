{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import openai\n",
    "from llama_index import VectorStoreIndex,SimpleDirectoryReader,StorageContext,load_index_from_storage,ServiceContext\n",
    "\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '4'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set logging info\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting api key\n",
    "#api key\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"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\"\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #token counting\n",
    "# from llama_index.callbacks import CallbackManager,TokenCountingHandler\n",
    "# import tiktoken\n",
    "\n",
    "# token_counter = TokenCountingHandler(\n",
    "#     tokenizer=tiktoken.encoding_for_model(\"text-embedding-ada-002\").encode,\n",
    "#     verbose=True\n",
    "# )\n",
    "# callback_manager = CallbackManager([token_counter])\n",
    "# service_context = ServiceContext.from_defaults(callback_manager=callback_manager)\n",
    "# service_context = ServiceContext.from_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Madhan\\Learnings\\LLamaIndexSamples\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 1.24MB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 184kB/s]\n",
      "README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 8.69MB/s]\n",
      "config.json: 100%|██████████| 571/571 [00:00<?, ?B/s] \n",
      "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<?, ?B/s] \n",
      "data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 321kB/s]\n",
      "pytorch_model.bin: 100%|██████████| 438M/438M [02:22<00:00, 3.08MB/s] \n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<?, ?B/s]\n",
      "special_tokens_map.json: 100%|██████████| 239/239 [00:00<?, ?B/s] \n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:01<00:00, 350kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 363/363 [00:00<?, ?B/s] \n",
      "train_script.py: 100%|██████████| 13.1k/13.1k [00:00<00:00, 10.1MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 460kB/s]\n",
      "modules.json: 100%|██████████| 349/349 [00:00<?, ?B/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\n",
      "Use pytorch device: cpu\n",
      "Use pytorch device: cpu\n",
      "Use pytorch device: cpu\n",
      "Use pytorch device: cpu\n",
      "Use pytorch device: cpu\n",
      "Use pytorch device: cpu\n",
      "Use pytorch device: cpu\n",
      "Use pytorch device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    }
   ],
   "source": [
    "#change embeddings\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.embeddings import LangchainEmbedding\n",
    "embed_model = LangchainEmbedding(\n",
    "    HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n",
    "# embedding = embed_model.get_text_embedding()\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading index from disk\n",
      "INFO:llama_index.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"./storage/cache/bot/profile/\")\n",
    "\n",
    "    #\n",
    "    print(\"loading index from disk\")\n",
    "    index = load_index_from_storage(storage_context)    \n",
    "\n",
    "except:\n",
    "    #    \n",
    "    print(\"index data not available in disk\")\n",
    "    print(\"getting list of documents from the storage\")\n",
    "    documents = SimpleDirectoryReader(\"./assets/profile\").load_data()\n",
    "\n",
    "    embedding = embed_model.get_text_embedding(documents)\n",
    "\n",
    "    print(\"creating index from documents\")\n",
    "    index = VectorStoreIndex.from_documents(documents,service_context=service_context)\n",
    "\n",
    "    print(\"writing index to disk\")\n",
    "    index.storage_context.persist(persist_dir=\"./storage/cache/bot/profile/\")    \n",
    "\n",
    "# print(token_counter.total_embedding_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating query engine from index\n"
     ]
    }
   ],
   "source": [
    "print(\"creating query engine from index\")\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "This document appears to be a profile or biography of a cricketer named Madhan Sekar. It provides information about his cricket career, including his debut matches, achievements, records, and captaincy roles. It also mentions his personal life, involvement in animal welfare campaigns, early life, and commercial endorsements.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"whats this document is about?\");\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
